# Orga.AI - Sua vida organizada com inteligÃªncia

## ğŸ“‹ VisÃ£o Geral

Orga.AI Ã© uma aplicaÃ§Ã£o moderna de produtividade que combina gerenciamento de tarefas com inteligÃªncia artificial para otimizar seu fluxo de trabalho. A plataforma utiliza tecnologias de ponta como Next.js, FastAPI, Supabase e modelos de IA para oferecer uma experiÃªncia Ãºnica de organizaÃ§Ã£o e automaÃ§Ã£o.

## âœ¨ Funcionalidades Principais

### Funcionalidades-Chave (MVP)
- **Painel Kanban com IA**: CriaÃ§Ã£o automÃ¡tica de cards a partir de e-mails, mensagens ou voz
- **To-do List com Prioridade Inteligente**: OrganizaÃ§Ã£o automÃ¡tica por urgÃªncia, energia e tempo
- **CalendÃ¡rio Integrado**: SincronizaÃ§Ã£o com Google Calendar e sugestÃµes de reorganizaÃ§Ã£o
- **Alertas Inteligentes**: NotificaÃ§Ãµes via WhatsApp ou e-mail baseadas em hÃ¡bitos e prazos
- **Assistente IA**:
  - CriaÃ§Ã£o de tarefas por comando de voz ou texto
  - SugestÃµes de reorganizaÃ§Ã£o de agenda
  - RedaÃ§Ã£o/resposta de e-mails e mensagens no WhatsApp com base em contexto
  - GeraÃ§Ã£o de resumos semanais e planos de aÃ§Ã£o
  - **Prompts Salvos**: Armazenamento e reutilizaÃ§Ã£o de prompts frequentes

### Dashboard de Acompanhamento com IA
- **Indicadores principais**:
  - Tarefas cumpridas e nÃ£o cumpridas
  - Tarefas atrasadas
  - Metas alcanÃ§adas e pendentes
  - Tarefas em andamento (por status ou tag)
  - Horas de foco real (calculado via padrÃ£o de uso ou timer com IA)
- **VisÃ£o GrÃ¡fica**:
  - GrÃ¡fico da semana (atividades por dia, calor de produtividade)
  - GrÃ¡fico de foco (pomodoro, tempo de dedicaÃ§Ã£o, interrupÃ§Ãµes)

### FunÃ§Ãµes AvanÃ§adas de Replanejamento com IA
- IA detecta sobrecarga, atraso, ou padrÃµes negativos
  - Sugere redistribuiÃ§Ã£o de tarefas
  - Proporcionalmente ajusta prazos com base na rotina
  - Prioriza metas crÃ­ticas e envia alertas para realinhamento

## ğŸ§  Sistema AvanÃ§ado de Chat com IA

### Arquitetura de Chat Inteligente
O sistema de chat utiliza uma combinaÃ§Ã£o sofisticada de tecnologias:

1. **Sistema HÃ­brido de Processamento**:
   - **Reconhecimento de IntenÃ§Ã£o**: Processamento rÃ¡pido de comandos simples
   - **RAG (Retrieval Augmented Generation)**: Enriquecimento de contexto com dados do usuÃ¡rio
   - **LLM (Large Language Model)**: Processamento avanÃ§ado via Ollama

2. **Funcionalidades do Chat**:
   - **HistÃ³rico de Conversas**: Armazenamento e recuperaÃ§Ã£o do histÃ³rico de interaÃ§Ãµes
   - **Prompts Salvos**: Biblioteca de prompts frequentes personalizÃ¡veis
   - **SugestÃ£o de Tags**: CategorizaÃ§Ã£o automÃ¡tica de conversas
   - **Streaming de Respostas**: Feedback em tempo real para melhor experiÃªncia

3. **SugestÃ£o de Atributos de Tarefas**:
   - AnÃ¡lise inteligente para sugerir prioridade, tags e tempo estimado
   - ExtraÃ§Ã£o automÃ¡tica de elementos chave das tarefas

### Gerenciamento de Prompts Salvos
- Interface dedicada para adicionar, visualizar e reutilizar prompts
- OrganizaÃ§Ã£o por categorias e tags
- Acesso rÃ¡pido aos prompts mais utilizados
- Diferentes limites de armazenamento por plano de assinatura

## ğŸ›  Stack TecnolÃ³gica

### Frontend
- Next.js 14
- React 18
- TailwindCSS
- Framer Motion
- Supabase Client
- Zustand (Gerenciamento de estado)

### Backend
- FastAPI
- Python 3.12
- SQLAlchemy
- LlamaIndex
- Transformers
- Torch

### Infraestrutura
- Docker & Docker Compose
- Supabase (PostgreSQL)
- Kong API Gateway
- N8N (AutomaÃ§Ã£o)

### IA/Agente
- Ollama (llama3, mistral, neural-chat)
- Langchain
- RAG com dados do usuÃ¡rio
- Modelos de linguagem avanÃ§ados
- Sentence Transformers para embeddings

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Docker e Docker Compose
- Git
- Node.js 18+ (para desenvolvimento)
- Python 3.11+ (para desenvolvimento)

### Scripts Principais
- `./scripts/reinstall.sh` â€“ Limpa volumes, rebuild e inicia todos os serviÃ§os
- `./scripts/sh/start.sh [--frontend-only] [--backend-only] [--no-docker]` â€“ Inicia o projeto em modo desenvolvimento com Docker
- `./scripts/sh/run-migrations.sh` â€“ Executa todos os scripts em `scripts/sql`
- `./scripts/sh/init-ollama.sh` â€“ Inicializa o servidor Ollama e baixa os modelos necessÃ¡rios
- `./scripts/sh/push-ollama-model.sh` â€“ Gerencia o download de modelos especÃ­ficos do Ollama
- `./scripts/sh/apply_all_fixes.sh` - Aplica todas as correÃ§Ãµes de banco de dados e configuraÃ§Ã£o (ver [documentaÃ§Ã£o de correÃ§Ãµes](docs/FIXES_MAY_13_2025.md))

### Desenvolvimento

#### Frontend
```bash
cd frontend
npm install
npm run dev
```

#### Backend
```bash
cd backend
python -m venv .venv
source .venv/bin/activate  # ou .venv\Scripts\activate no Windows
pip install -r requirements.txt
uvicorn app.main:app --reload
```

### ConfiguraÃ§Ã£o do Ambiente
1. **ConfiguraÃ§Ã£o inicial**: 
   ```bash
   cp .env.example .env
   ```
2. **Edite o arquivo .env** com suas configuraÃ§Ãµes especÃ­ficas:
   - `OLLAMA_MODEL`: Modelo principal (padrÃ£o: "gemma3:1b")
   - `OLLAMA_MODEL_CHAT`: Modelo de chat (padrÃ£o: "gemma3:1b")
   - Credenciais do banco de dados e serviÃ§os

### Acessando os ServiÃ§os
- Frontend: http://localhost:3010
- Backend API: http://localhost:8000/api/docs
- Supabase Studio: http://localhost:54323
- N8N: http://localhost:5678
- Open-WebUI (Interface Ollama): http://localhost:3000
- Ollama API: http://localhost:11434

### Acesso via Rede Local
Para acessar a aplicaÃ§Ã£o de outros dispositivos na mesma rede:
1. Use o IP local da mÃ¡quina host (ex: http://192.168.0.10:3010)
2. As configuraÃ§Ãµes CORS e de rede jÃ¡ estÃ£o ajustadas para permitir acesso remoto

## ğŸ“¦ Estrutura do Projeto
```
orga-ai-v4/
â”œâ”€â”€ frontend/              # AplicaÃ§Ã£o Next.js
â”‚   â”œâ”€â”€ app/               # Componentes, serviÃ§os e lÃ³gica da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ components/    # Componentes React reutilizÃ¡veis
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat.tsx   # Componente de chat com IA e prompts salvos
â”‚   â”‚   â”‚   â”œâ”€â”€ SavedPrompts.tsx # Componente para prompts salvos
â”‚   â”‚   â”œâ”€â”€ services/      # ServiÃ§os de API e integraÃ§Ã£o
â”‚   â”‚   â”‚   â”œâ”€â”€ chatService.ts # ServiÃ§o para API de chat
â”‚   â”‚   â””â”€â”€ contexts/      # Contextos React (auth, prompt)
â”œâ”€â”€ backend/               # API FastAPI
â”‚   â”œâ”€â”€ app/               # CÃ³digo principal da API
â”‚   â”‚   â”œâ”€â”€ routers/       # Rotas da API (chat, chat_stream, etc.)
â”‚   â”‚   â”œâ”€â”€ services/      # ServiÃ§os (ai_service, vector_store, etc.)
â”‚   â”‚   â””â”€â”€ models/        # Modelos de dados
â”œâ”€â”€ cookbooks/             # ConfiguraÃ§Ãµes e modelos de IA
â”œâ”€â”€ scripts/               # Scripts utilitÃ¡rios
â”œâ”€â”€ supabase/              # ConfiguraÃ§Ãµes Supabase e migraÃ§Ãµes
â”œâ”€â”€ volumes/               # Volumes Docker persistentes
â”œâ”€â”€ docker/                # Arquivos Dockerfile adicionais
â””â”€â”€ README.md              # Esta documentaÃ§Ã£o
```

## ğŸ§  Gerenciamento de Modelos Ollama

### Armazenamento de Modelos
Os modelos Ollama sÃ£o baixados e armazenados em:
- **No Docker**: Os modelos sÃ£o baixados dentro do container e persistidos no volume `./volumes/ollama_data` mapeado para `/root/.ollama` no container
- **Localmente**: Os modelos ficam disponÃ­veis entre reinicializaÃ§Ãµes graÃ§as Ã  persistÃªncia do volume

### Comandos para Gerenciar Modelos
- **Listar modelos instalados**:
  ```bash
  ./scripts/sh/push-ollama-model.sh --list
  ```

- **Baixar modelo especÃ­fico**:
  ```bash
  ./scripts/sh/push-ollama-model.sh --model llama3:8b
  ```

- **Baixar modelo de chat**:
  ```bash
  ./scripts/sh/push-ollama-model.sh --chat-model
  ```

- **Baixar todos os modelos configurados**:
  ```bash
  ./scripts/sh/push-ollama-model.sh --all
  ```

### Modelos Recomendados
- `gemma3:1b`: Modelo principal leve (815MB) com boa performance
- `phi3:mini`: Alternativa compacta para sistemas com recursos limitados
- `llama3:8b`: OpÃ§Ã£o mais robusta quando hÃ¡ recursos disponÃ­veis

## ğŸ’° Modelo de NegÃ³cio
1. **Free Forever**: Tarefas ilimitadas, IA local, 3 gatilhos, Google Calendar, painel bÃ¡sico, atÃ© 5 prompts salvos (R$ 0)
2. **Pro (SaaS)**: IA turbinada com RAG, replanejamento automÃ¡tico, alertas dinÃ¢micos, prompts salvos ilimitados (R$ 29/mÃªs)
3. **Business/Team**: ColaboraÃ§Ã£o, metas por grupo, bibliotecas de prompts compartilhados (R$ 69/mÃªs/usuÃ¡rio)

## ğŸ—º Roadmap
### Fase 1 - MVP (ConcluÃ­do)
- [x] AutenticaÃ§Ã£o bÃ¡sica
- [x] CRUD de tarefas
- [x] Interface responsiva
- [x] IntegraÃ§Ã£o com IA
- [x] Scripts de automaÃ§Ã£o
- [x] Estrutura de logs
- [x] Funcionalidade de chat com IA
- [x] Prompts salvos

### Fase 2 - Melhorias (Em Andamento)
- [x] Sistema de scripts organizado
- [x] Logs com timestamp
- [x] Tratamento de erros robusto
- [x] Acesso remoto via rede local
- [ ] Sistema de tags
- [ ] Filtros avanÃ§ados
- [ ] ExportaÃ§Ã£o de dados
- [ ] Melhorias na IA

### Fase 3 - Enterprise
- [ ] SSO/SAML
- [ ] API GraphQL
- [ ] White-label
- [ ] CustomizaÃ§Ã£o avanÃ§ada

## ğŸ¤ Contribuindo
1. Fork o projeto
2. Crie sua Feature Branch (`git checkout -b feature/NovaFuncionalidade`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova funcionalidade'`)
4. Push para a Branch (`git push origin feature/NovaFuncionalidade`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a
Licenciado sob MIT (veja LICENSE)

---

Desenvolvido com â¤ï¸ pela equipe Orga.AI | Atualizado em maio/2025

