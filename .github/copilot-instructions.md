# Orga.AI - Sua vida organizada com inteligÃªncia 

## ğŸ“‹ VisÃ£o Geral

Orga.AI Ã© uma aplicaÃ§Ã£o moderna de produtividade que combina gerenciamento de tarefas com inteligÃªncia artificial para otimizar seu fluxo de trabalho. A plataforma utiliza tecnologias de ponta como Next.js, FastAPI, Supabase e modelos de IA para oferecer uma experiÃªncia Ãºnica de organizaÃ§Ã£o e automaÃ§Ã£o.

## âœ¨ Funcionalidades Principais

### Funcionalidades-Chave (MVP)
- **Painel Kanban com IA**: CriaÃ§Ã£o automÃ¡tica de cards a partir de e-mails, mensagens ou voz
- **To-do List com Prioridade Inteligente**: OrganizaÃ§Ã£o automÃ¡tica por urgÃªncia, energia e tempo
- **CalendÃ¡rio Integrado**: SincronizaÃ§Ã£o com Google Calendar e sugestÃµes de reorganizaÃ§Ã£o
- **Alertas Inteligentes**: NotificaÃ§Ãµes via WhatsApp ou e-mail baseadas em hÃ¡bitos e prazos
- **Assistente IA**: 
  - CriaÃ§Ã£o de tarefas por comando de voz ou texto
  - SugestÃµes de reorganizaÃ§Ã£o de agenda
  - RedaÃ§Ã£o/resposta de e-mails e mensagens no WhatsApp com base em contexto
  - GeraÃ§Ã£o de resumos semanais e planos de aÃ§Ã£o
  - **Prompts Salvos**: Armazenamento e reutilizaÃ§Ã£o de prompts frequentes para interaÃ§Ãµes rÃ¡pidas

### Dashboard de Acompanhamento com IA
- **Indicadores principais**:
  - Tarefas cumpridas e nÃ£o cumpridas
  - Tarefas atrasadas
  - Metas alcanÃ§adas e pendentes
  - Tarefas em andamento (por status ou tag)
  - Horas de foco real (calculado via padrÃ£o de uso ou timer com IA)
- **VisÃ£o GrÃ¡fica**:
  - GrÃ¡fico da semana (atividades por dia, calor de produtividade)
  - GrÃ¡fico de foco (pomodoro, tempo de dedicaÃ§Ã£o, interrupÃ§Ãµes)

### FunÃ§Ãµes AvanÃ§adas de Replanejamento com IA
- IA detecta sobrecarga, atraso, ou padrÃµes negativos
  - Sugere redistribuiÃ§Ã£o de tarefas
  - Proporcionalmente ajusta prazos com base na rotina
  - Prioriza metas crÃ­ticas e envia alertas para realinhamento

## ğŸ§  Sistema AvanÃ§ado de Chat com IA

### Arquitetura de Processamento de Linguagem
O sistema de chat Ã© construÃ­do com uma arquitetura sofisticada de mÃºltiplos nÃ­veis:

1. **Sistema HÃ­brido de Processamento**:
   - **Detector de IntenÃ§Ãµes**: MÃ³dulo de classificaÃ§Ã£o rÃ¡pida que identifica comandos simples e os processa sem acionar o LLM completo
   - **Sistema RAG (Retrieval Augmented Generation)**: 
     - Armazena dados do usuÃ¡rio em um banco de embeddings
     - Utiliza Sentence Transformers para transformar texto em vetores
     - Recupera contexto relevante para enriquecer as interaÃ§Ãµes
   - **Processador LLM**: Utiliza modelos Ollama para processamento de linguagem avanÃ§ado

2. **Componentes Principais do Sistema de Chat**:
   - **HistÃ³rico de Chat**: Sistema de armazenamento e recuperaÃ§Ã£o do histÃ³rico de conversas
   - **Gerenciador de Prompts Salvos**: Biblioteca personalizada de prompts frequentes
   - **Processador de Streaming**: Entrega respostas em tempo real via FastAPI EventSource
   - **SugestÃ£o de Atributos**: ExtraÃ§Ã£o inteligente de metadados para tarefas

### ImplementaÃ§Ã£o TÃ©cnica do Sistema de RAG
- **Armazenamento de Vetores**: Implementado com FAISS para busca eficiente
- **Transformadores de Embeddings**: Modelos leves de Sentence Transformers (all-MiniLM-L6-v2)
- **Contexto Personalizado**: IncorporaÃ§Ã£o de dados do usuÃ¡rio para respostas mais relevantes
- **Processamento AssÃ­ncrono**: Sistema de filas para processamento eficiente de solicitaÃ§Ãµes
- **Cache Inteligente**: Armazenamento temporÃ¡rio de embeddings frequentes para reduzir latÃªncia

### Sistema de Prompts Salvos
- **Interface de Gerenciamento**: Componente React dedicado para gerenciar prompts
- **Armazenamento**: Prompts salvos no banco Supabase com relaÃ§Ã£o ao usuÃ¡rio
- **CategorizaÃ§Ã£o**: Sistema de tags para organizaÃ§Ã£o dos prompts por temas
- **Acesso RÃ¡pido**: Interface de pesquisa e favoritos para prompts frequentes
- **Limites por Plano**: Diferentes capacidades de armazenamento por assinatura (5 no Free, ilimitados no Pro)

### Fluxo de Processamento de Chat
1. UsuÃ¡rio envia mensagem via componente Chat.tsx
2. Backend processa via rotas chat.py ou chat_stream.py
3. Sistema de detecÃ§Ã£o de intenÃ§Ã£o verifica se Ã© um comando simples
4. Se necessÃ¡rio, RAG recupera contexto relevante do histÃ³rico e dados do usuÃ¡rio
5. LLM processa a solicitaÃ§Ã£o enriquecida com o contexto
6. Resposta Ã© entregue progressivamente via streaming ou completa

## ğŸ›  Stack TecnolÃ³gica

### Frontend
- Next.js 14
- React 18
- TailwindCSS
- Framer Motion
- Supabase Client
- Zustand (Gerenciamento de estado)
- React Hook Form (FormulÃ¡rios)

### Backend
- FastAPI
- Python 3.12
- SQLAlchemy
- LlamaIndex
- Transformers
- Torch

### Infraestrutura
- Docker & Docker Compose
- Supabase (PostgreSQL)
- Kong API Gateway
- N8N (AutomaÃ§Ã£o)

### IA/Agente
- Ollama (llama3, mistral, neural-chat)
- Langchain
- RAG com dados do usuÃ¡rio
- Modelos de linguagem avanÃ§ados

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Docker e Docker Compose
- Git
- Node.js 18+ (para desenvolvimento)
- Python 3.11+ (para desenvolvimento)

### Scripts Principais
- `./scripts/reinstall.sh` â€“ Limpa volumes, rebuild e inicia todos os serviÃ§os
- `./scripts/sh/start.sh [--frontend-only] [--backend-only] [--no-docker]` â€“ Inicia o projeto em modo desenvolvimento com Docker
- `./scripts/sh/run-migrations.sh` â€“ Executa todos os scripts em `scripts/sql`
- `./scripts/sh/init-ollama.sh` â€“ Inicializa o servidor Ollama e baixa os modelos necessÃ¡rios
- `./scripts/sh/push-ollama-model.sh` â€“ Gerencia o download de modelos especÃ­ficos do Ollama

### Desenvolvimento

#### Frontend
```bash
cd frontend
npm install
npm run dev
```

#### Backend
```bash
cd backend
python -m venv .venv
source .venv/bin/activate  # ou .venv\Scripts\activate no Windows
pip install -r requirements.txt
uvicorn app.main:app --reload
```

### ConfiguraÃ§Ã£o do Ambiente
1. **ConfiguraÃ§Ã£o inicial**: 
   ```bash
   cp .env.example .env
   ```
2. **Edite o arquivo .env** com suas configuraÃ§Ãµes especÃ­ficas:
   - `OLLAMA_MODEL`: Modelo principal (padrÃ£o: "gemma3:1b")
   - `OLLAMA_MODEL_CHAT`: Modelo de chat (padrÃ£o: "gemma3:1b")
   - `OLLAMA_BASE_URL`: URL do servidor Ollama
   - Credenciais do banco de dados e serviÃ§os

### Acessando
- Frontend: http://localhost:3010
- Backend API: http://localhost:8000/api/docs
- Supabase Studio: http://localhost:54323
- N8N: http://localhost:5678
- Open-WebUI (Interface Ollama): http://localhost:3000
- Ollama API: http://localhost:11434

### Acesso via Rede Local
Para acessar a aplicaÃ§Ã£o de outros dispositivos na mesma rede:
1. Use o IP local da mÃ¡quina host (ex: http://192.168.0.10:3010)
2. As configuraÃ§Ãµes CORS no back-end jÃ¡ estÃ£o configuradas para permitir acesso de qualquer origem
3. As URLs da API no front-end sÃ£o geradas dinamicamente com base no hostname atual

## ğŸ“¦ Estrutura do Projeto
```
orga-ai-v4/
â”œâ”€â”€ frontend/              # AplicaÃ§Ã£o Next.js
â”‚   â”œâ”€â”€ app/               # Componentes, serviÃ§os e lÃ³gica da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ components/    # Componentes React reutilizÃ¡veis
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat.tsx   # Componente de chat com IA e prompts salvos
â”‚   â”‚   â”‚   â”œâ”€â”€ SavedPrompts.tsx # Componente para gerenciar prompts salvos
â”‚   â”‚   â”‚   â””â”€â”€ ...        # Outros componentes
â”‚   â”‚   â”œâ”€â”€ services/      # ServiÃ§os de API e integraÃ§Ã£o
â”‚   â”‚   â”‚   â”œâ”€â”€ chatService.ts # ServiÃ§o para comunicaÃ§Ã£o com a API de chat
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts     # ConfiguraÃ§Ã£o base da API
â”‚   â”‚   â”‚   â””â”€â”€ ...        # Outros serviÃ§os
â”‚   â”‚   â””â”€â”€ contexts/      # Contextos React
â”‚   â”‚       â”œâ”€â”€ AuthContext.tsx # Contexto de autenticaÃ§Ã£o
â”‚   â”‚       â”œâ”€â”€ PromptContext.tsx # Contexto para gerenciamento de prompts
â”‚   â”‚       â””â”€â”€ ...        # Outros contextos
â”œâ”€â”€ backend/               # API FastAPI
â”‚   â”œâ”€â”€ app/               # CÃ³digo principal da API
â”‚   â”‚   â”œâ”€â”€ routers/       # Rotas da API
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py    # Rotas para o chat e prompts salvos
â”‚   â”‚   â”‚   â”œâ”€â”€ chat_stream.py # Rotas para streaming de respostas
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py    # Rotas de autenticaÃ§Ã£o
â”‚   â”‚   â”‚   â””â”€â”€ ...        # Outras rotas
â”‚   â”‚   â”œâ”€â”€ services/      # ServiÃ§os 
â”‚   â”‚   â”‚   â”œâ”€â”€ ai_service.py # ServiÃ§o principal de IA
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store.py # Gerenciamento de vetores para RAG
â”‚   â”‚   â”‚   â”œâ”€â”€ intent_recognizer.py # ClassificaÃ§Ã£o de intenÃ§Ãµes
â”‚   â”‚   â”‚   â”œâ”€â”€ stream_service.py # ServiÃ§o de streaming de respostas
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_service.py # ServiÃ§o de autenticaÃ§Ã£o
â”‚   â”‚   â”‚   â””â”€â”€ ...        # Outros serviÃ§os
â”‚   â”‚   â””â”€â”€ models/        # Modelos de dados
â”‚   â”‚       â”œâ”€â”€ chat.py    # Modelo para histÃ³rico de chat e prompts salvos
â”‚   â”‚       â”œâ”€â”€ user.py    # Modelo de usuÃ¡rio
â”‚   â”‚       â””â”€â”€ ...        # Outros modelos
â”œâ”€â”€ cookbooks/             # ConfiguraÃ§Ãµes e modelos de IA
â”‚   â”œâ”€â”€ Modelfile          # ConfiguraÃ§Ã£o dos modelos Ollama
â”‚   â””â”€â”€ models/            # Modelos de IA prÃ©-configurados
â”œâ”€â”€ scripts/               # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ sh/                # Shell scripts
â”‚   â”‚   â”œâ”€â”€ start.sh       # Inicia o projeto
â”‚   â”‚   â”œâ”€â”€ init-ollama.sh # Inicializa o servidor Ollama
â”‚   â”‚   â”œâ”€â”€ push-ollama-model.sh # Gerencia modelos do Ollama
â”‚   â”‚   â””â”€â”€ ...            # Outros scripts shell
â”‚   â””â”€â”€ sql/               # Scripts SQL
â”‚       â”œâ”€â”€ init.sql       # InicializaÃ§Ã£o do banco
â”‚       â”œâ”€â”€ fix_chat_history.sql # CorreÃ§Ãµes para tabela de histÃ³rico de chat
â”‚       â””â”€â”€ ...            # Outros scripts SQL
â”œâ”€â”€ supabase/              # ConfiguraÃ§Ãµes Supabase e migraÃ§Ãµes
â”‚   â””â”€â”€ migrations/        # MigraÃ§Ãµes do banco de dados 
â”œâ”€â”€ volumes/               # Volumes Docker persistentes
â”‚   â”œâ”€â”€ db/                # Dados do PostgreSQL
â”‚   â””â”€â”€ ollama_data/       # Modelos e dados do Ollama
â”œâ”€â”€ docker/                # Arquivos Dockerfile adicionais
â”œâ”€â”€ .github/               # ConfiguraÃ§Ãµes GitHub
â”œâ”€â”€ docker-compose.yml     # OrquestraÃ§Ã£o dos serviÃ§os
â””â”€â”€ README.md              # DocumentaÃ§Ã£o principal
```

## ğŸ§  Gerenciamento de Modelos Ollama

### Armazenamento e ConfiguraÃ§Ã£o
Os modelos Ollama sÃ£o armazenados no volume `./volumes/ollama_data` mapeado para `/root/.ollama` dentro do container Docker. A persistÃªncia Ã© garantida entre reinicializaÃ§Ãµes graÃ§as ao mapeamento de volumes.

### Scripts de Gerenciamento
- `init-ollama.sh`: Inicializa o servidor Ollama e baixa os modelos padrÃ£o configurados
- `push-ollama-model.sh`: Oferece uma interface para gerenciar modelos

### Comandos Ãšteis
- Listar modelos instalados: `./scripts/sh/push-ollama-model.sh --list`
- Baixar modelo especÃ­fico: `./scripts/sh/push-ollama-model.sh --model llama3:8b`
- Baixar modelo de chat: `./scripts/sh/push-ollama-model.sh --chat-model`
- Baixar todos os modelos: `./scripts/sh/push-ollama-model.sh --all`

### Modelos Recomendados e Casos de Uso
- `mistral:7b-instruct`: Ideal para tarefas gerais de processamento de linguagem natural, anÃ¡lise de texto e raciocÃ­nio lÃ³gico
- `neural-chat:latest`: Especializado em interaÃ§Ãµes conversacionais fluidas e naturais, Ã³timo para o assistente de chat
- `llama3:8b`: VersÃ£o equilibrada entre performance e qualidade, indicada para quando recursos de hardware sÃ£o limitados
- `phi-3:mini`: Modelo compacto para dispositivos de menor capacidade, com boa performance para tarefas simples 
- `mixtral:instruct`: Modelo mais robusto para tarefas complexas quando recursos de hardware permitem

## ğŸ”§ PadrÃµes e Boas PrÃ¡ticas

### Frontend
- **Componentes**: Seguir padrÃ£o de componentes funcionais com hooks
- **Estados**: Usar Zustand para estado global, useState para estado local
- **FormulÃ¡rios**: Utilizar React Hook Form para gerenciamento de formulÃ¡rios
- **API**: Usar os serviÃ§os em `/services` para comunicaÃ§Ãµes com o backend
- **EstilizaÃ§Ã£o**: TailwindCSS para estilos, componentes do shadcn/ui

### Backend
- **Rotas**: Divididas por recurso (chat, auth, tasks, etc.)
- **ServiÃ§os**: LÃ³gica de negÃ³cio encapsulada em serviÃ§os
- **Modelos**: DefiniÃ§Ã£o das tabelas e relacionamentos
- **Schemas**: ValidaÃ§Ã£o de dados com Pydantic
- **InjeÃ§Ã£o de DependÃªncias**: Usar sistema de dependÃªncias do FastAPI

### Banco de Dados
- **MigraÃ§Ãµes**: Arquivos SQL em `/supabase/migrations`
- **CorreÃ§Ãµes**: Scripts SQL especÃ­ficos em `/scripts/sql`
- **RelaÃ§Ãµes**: Definidas explicitamente nos modelos SQLAlchemy

### IA e Modelos
- **ConfiguraÃ§Ã£o**: VariÃ¡veis de ambiente ou arquivos em `/cookbooks`
- **Prompts**: Centralizar templates de prompts para consistÃªncia em `backend/app/templates/prompts`
- **RAG**: ImplementaÃ§Ãµes em `backend/app/services/ai_service.py` e `vector_store.py`
- **Embeddings**: Utilizar modelos da biblioteca Sentence Transformers
- **Streaming**: Implementar com SSE (Server-Sent Events) via FastAPI

## ğŸ’° Modelo de NegÃ³cio

### Planos de Assinatura

1. **Free Forever**
   - Tarefas ilimitadas
   - IA local (via Ollama)
   - AtÃ© 3 gatilhos ativos
   - IntegraÃ§Ã£o com Google Calendar
   - Painel bÃ¡sico de produtividade
   - AtÃ© 5 prompts salvos
   - PreÃ§o: R$ 0

2. **Pro (SaaS)**
   - IA turbinada (com RAG, contexto pessoal e histÃ³rico)
   - Replanejamento automÃ¡tico
   - Alertas dinÃ¢micos
   - Painel completo
   - RelatÃ³rios e insights personalizados
   - Prompts salvos ilimitados
   - PreÃ§o: R$ 29/mÃªs

3. **Business/Team**
   - ColaboraÃ§Ã£o entre times
   - Assistente de IA para gestÃ£o de equipe
   - Metas por grupo
   - RelatÃ³rios integrados
   - Alertas compartilhÃ¡veis
   - Bibliotecas de prompts compartilhados
   - PreÃ§o: R$ 69/mÃªs/usuÃ¡rio

## ğŸ—º Roadmap

### Fase 1 - MVP (ConcluÃ­do)
- [x] AutenticaÃ§Ã£o bÃ¡sica
- [x] CRUD de tarefas
- [x] Interface responsiva
- [x] IntegraÃ§Ã£o com IA
- [x] Scripts de automaÃ§Ã£o
- [x] Estrutura de logs
- [x] Funcionalidade de chat com IA
- [x] Prompts salvos
- [x] Acesso via rede local

### Fase 2 - Melhorias (Em Andamento)
- [x] Sistema de scripts organizado
- [x] Logs com timestamp
- [x] Tratamento de erros robusto
- [x] Componente de prompts salvos
- [ ] Sistema de tags
- [ ] Filtros avanÃ§ados
- [ ] ExportaÃ§Ã£o de dados
- [ ] Melhorias na IA

### Fase 3 - Enterprise
- [ ] SSO/SAML
- [ ] API GraphQL
- [ ] White-label
- [ ] CustomizaÃ§Ã£o avanÃ§ada

## ğŸ“ Scripts e UtilitÃ¡rios

### Scripts Shell
- `start.sh`: Inicia todos os serviÃ§os
- `reinstall.sh`: Reinstala todo o ambiente
- `init-db.sh`: Inicializa o banco de dados
- `wait-for-postgres.sh`: Aguarda PostgreSQL
- `init-gotrue.sh`: Configura autenticaÃ§Ã£o
- `init-ollama.sh`: Inicializa o servidor Ollama
- `push-ollama-model.sh`: Gerencia modelos Ollama
- `health-check.sh`: Verifica saÃºde dos serviÃ§os

### Scripts SQL
- `init.sql`: InicializaÃ§Ã£o do banco
- `clean.sql`: Limpeza de dados
- `fix-auth.sql`: CorreÃ§Ãµes de autenticaÃ§Ã£o
- `fix_chat_history.sql`: CorreÃ§Ãµes para tabela de histÃ³rico de chat
- `fix_timestamps.sql`: CorreÃ§Ãµes para campos de timestamp

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie sua Feature Branch (`git checkout -b feature/NovaFuncionalidade`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova funcionalidade'`)
4. Push para a Branch (`git push origin feature/NovaFuncionalidade`)
5. Abra um Pull Request

### Fluxo de trabalho para contribuidores
1. Clone o repositÃ³rio: `git clone https://github.com/seu-usuario/orga-ai-v4.git`
2. Instale as dependÃªncias (frontend e backend)
3. Crie uma branch para sua feature: `git checkout -b feature/nova-funcionalidade`
4. Implemente suas alteraÃ§Ãµes seguindo os padrÃµes de cÃ³digo
5. Execute os testes: `npm test` (frontend) e `pytest` (backend)
6. FaÃ§a commit das alteraÃ§Ãµes: `git commit -m "Implemente nova funcionalidade XYZ"`
7. Envie para o GitHub: `git push origin feature/nova-funcionalidade`
8. Crie um Pull Request no GitHub descrevendo suas alteraÃ§Ãµes

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](../LICENSE) para detalhes.

---

Desenvolvido com â¤ï¸ pela equipe Orga.AI | Atualizado em maio/2025

